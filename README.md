# ğŸ“„ Resume Filtering v2

An **agentic AI workflow** for automated resume filtering.
This project parses job descriptions and resumes stored in **Supabase**, extracts structured information using **LLMs**, and generates a **compatibility score** with an **audit report** â€” helping recruiters quickly identify the best candidates.

---

## ğŸš€ Features

* **Job Description Agent** â†’ Extracts structured requirements from job description PDFs.
* **Resume Parser Agent** â†’ Parses resumes into structured JSON.
* **Compatibility Analyzer** â†’ Compares parsed resume data with job requirements.
* **Audit Agent** â†’ Produces a final audit explaining compatibility decisions.
* **Supabase Integration** â†’ Stores job documents, parsed resumes, and results.
* **Token & Cost Tracking** â†’ Logs LLM usage and estimates costs per agent.

---

## ğŸ“‚ Project Structure

```
resume_filtering_v2/
â”‚â”€â”€ main.py                  # Entry point: runs the entire workflow
â”‚â”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ agents/                  # (Optional extension for agent definitions)
â”œâ”€â”€ prompts/                 # Prompt templates for each agent
â”‚   â”œâ”€â”€ job_description_prompt.txt
â”‚   â”œâ”€â”€ resume_parser_prompt.txt
â”‚   â”œâ”€â”€ compatibility_prompt.txt
â”‚   â””â”€â”€ audit_agent.txt
â”‚
â”œâ”€â”€ util/
â”‚   â”œâ”€â”€ supabase_utils.py    # Supabase upload/download helpers
â”‚   â””â”€â”€ parsing.py           # Resume & JD text parsing utilities
â”‚
â””â”€â”€ job_folders/             # Example job/resume storage (mirrors Supabase bucket)
```

---

## âš™ï¸ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/awinpavan/resume_filtering_v2.git
cd resume_filtering_v2
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Environment Variables

Create a `.env` file in the project root with:

```env
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_service_role_key
GROQ_API_KEY=your_groq_api_key
```

---

## â–¶ï¸ Usage

Run the workflow:

```bash
python main.py
```

**Workflow steps:**

1. Lists available job folders from Supabase (`job-documents/`).
2. Lets you select a job folder.
3. Parses job description and resumes (if not already parsed).
4. Runs agentic pipeline:

   * Extract job requirements
   * Parse resumes
   * Compute compatibility scores
   * Generate audit report
5. Uploads structured results back to Supabase.
6. Prints token usage & cost summary.

---

## ğŸ§‘â€ğŸ’» Example Output

```
==== Resume Filtering Agentic Workflow ====
ğŸ“‚ Available Job Folders:
1. ai_engineer
2. data_scientist

ğŸ‘‰ Select a job folder number to view details: 1

ğŸ“„ Job Description(s):
â€¢ job_ai_engineer.pdf â†’ https://...

ğŸ“ Resumes:
â€¢ resume_1.pdf â†’ https://...
â€¢ resume_2.pdf â†’ https://...

ğŸ”„ Now parsing and uploading documents for job: ai_engineer
...
[Compatibility Result]
{
  "score": 0.87,
  "fit": "High",
  "reasons": ["Matches required ML experience", "Good Python skills"]
}
[AuditAgent Output]
{
  "decision": "Fit",
  "explanation": "Resume aligns with 80%+ of core job requirements..."
}
==================== TOKEN & COST SUMMARY ====================
Agent                        Calls       Input      Output      Cost($)
job_description_agent            1         220         350       0.0008
resume_parser_agent              2         400         500       0.0014
compatibility_analyzer_agent     2         310         420       0.0011
audit_agent                      2         280         390       0.0010
-----------------------------------------------------------------------
TOTAL                            7        1210        1660       0.0043
============================================================
```

---

## ğŸ› ï¸ Tech Stack

* **Python 3.10+**
* [LangGraph](https://github.com/langchain-ai/langgraph)
* [LangChain](https://www.langchain.com/)
* [Groq API](https://groq.com/) for fast LLM inference
* [Supabase](https://supabase.com/) for storage

---

## ğŸ“Œ Next Steps / TODO

* [ ] Add Dockerfile for easy deployment
* [ ] Build a web UI to visualize compatibility reports
* [ ] Extend with recruiter feedback loop for continuous improvement

```

---

I can also create this as a **downloadable `README.md` file** for you right now so you can just save it in your repo. Do you want me to do that?

```
